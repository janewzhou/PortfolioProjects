{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import style\n",
    "# import seaborn as sns\n",
    "# import pylab\n",
    "import random \n",
    "from pandas import DataFrame\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import math\n",
    "from statistics import mode\n",
    "from collections import Counter\n",
    "from decimal import getcontext\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"C:/Users/janew/Desktop/DA Project/Quantium Project/Task 1/\"\n",
    "transactionData = pd.read_excel(filepath+\"QVI_transaction_data.xlsx\")\n",
    "customerData = pd.read_csv(filepath+\"QVI_purchase_behaviour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExamine Transaction Data, including the following:\\n    1. change DATE format from int64 to datetime format\\n    2. perform basic text analysis: remove special characters\\n    3. examine product names: remove products that are not chips, eg. salsa\\n    4. examine product quantity: remove those who purchased quantity greater than 200 in one transaction\\n    5. check missing dates: 2018-12-25 is missing due to Christmas shops closure\\n    6. check pack size or weight in each product, all products have reasonable pack sizes\\n\\nPerform summary statistics table\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Examine Transaction Data, including the following:\n",
    "    1. change DATE format from int64 to datetime format\n",
    "    2. perform basic text analysis: remove special characters\n",
    "    3. examine product names: remove products that are not chips, eg. salsa\n",
    "    4. examine product quantity: remove those who purchased quantity greater than 200 in one transaction\n",
    "    5. check missing dates: 2018-12-25 is missing due to Christmas shops closure\n",
    "    6. check pack size or weight in each product, all products have reasonable pack sizes\n",
    "\n",
    "Perform summary statistics table\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert DATE format from int64 to datetime format\n",
    "def formatDateInCsv(dataframe):\n",
    "    dataframe['DATE'] = pd.to_datetime(dataframe['DATE'], unit='D', origin='1899-12-30', errors='coerce')\n",
    "\n",
    "formatDateInCsv(transactionData)\n",
    "# transactionData['DATE'] = pd.to_datetime(transactionData['DATE'], unit='D', origin='1899-12-30', errors='coerce')\n",
    "# transactionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STORE_NBR</th>\n",
       "      <th>LYLTY_CARD_NBR</th>\n",
       "      <th>TXN_ID</th>\n",
       "      <th>PROD_NBR</th>\n",
       "      <th>PROD_NAME</th>\n",
       "      <th>PROD_QTY</th>\n",
       "      <th>TOT_SALES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Natural Chip        Compny SeaSalt175g</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>1</td>\n",
       "      <td>1307</td>\n",
       "      <td>348</td>\n",
       "      <td>66</td>\n",
       "      <td>CCs Nacho Cheese    175g</td>\n",
       "      <td>3</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1343</td>\n",
       "      <td>383</td>\n",
       "      <td>61</td>\n",
       "      <td>Smiths Crinkle Cut  Chips Chicken 170g</td>\n",
       "      <td>2</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>2</td>\n",
       "      <td>2373</td>\n",
       "      <td>974</td>\n",
       "      <td>69</td>\n",
       "      <td>Smiths Chip Thinly  S/Cream&amp;Onion 175g</td>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>2</td>\n",
       "      <td>2426</td>\n",
       "      <td>1038</td>\n",
       "      <td>108</td>\n",
       "      <td>Kettle Tortilla ChpsHny&amp;Jlpno Chili 150g</td>\n",
       "      <td>3</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264831</th>\n",
       "      <td>2019-03-09</td>\n",
       "      <td>272</td>\n",
       "      <td>272319</td>\n",
       "      <td>270088</td>\n",
       "      <td>89</td>\n",
       "      <td>Kettle Sweet Chilli And Sour Cream 175g</td>\n",
       "      <td>2</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264832</th>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>272</td>\n",
       "      <td>272358</td>\n",
       "      <td>270154</td>\n",
       "      <td>74</td>\n",
       "      <td>Tostitos Splash Of  Lime 175g</td>\n",
       "      <td>1</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264833</th>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>272</td>\n",
       "      <td>272379</td>\n",
       "      <td>270187</td>\n",
       "      <td>51</td>\n",
       "      <td>Doritos Mexicana    170g</td>\n",
       "      <td>2</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264834</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>272</td>\n",
       "      <td>272379</td>\n",
       "      <td>270188</td>\n",
       "      <td>42</td>\n",
       "      <td>Doritos Corn Chip Mexican Jalapeno 150g</td>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264835</th>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>272</td>\n",
       "      <td>272380</td>\n",
       "      <td>270189</td>\n",
       "      <td>74</td>\n",
       "      <td>Tostitos Splash Of  Lime 175g</td>\n",
       "      <td>2</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264836 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  STORE_NBR  LYLTY_CARD_NBR  TXN_ID  PROD_NBR  \\\n",
       "0      2018-10-17          1            1000       1         5   \n",
       "1      2019-05-14          1            1307     348        66   \n",
       "2      2019-05-20          1            1343     383        61   \n",
       "3      2018-08-17          2            2373     974        69   \n",
       "4      2018-08-18          2            2426    1038       108   \n",
       "...           ...        ...             ...     ...       ...   \n",
       "264831 2019-03-09        272          272319  270088        89   \n",
       "264832 2018-08-13        272          272358  270154        74   \n",
       "264833 2018-11-06        272          272379  270187        51   \n",
       "264834 2018-12-27        272          272379  270188        42   \n",
       "264835 2018-09-22        272          272380  270189        74   \n",
       "\n",
       "                                       PROD_NAME  PROD_QTY  TOT_SALES  \n",
       "0         Natural Chip        Compny SeaSalt175g         2        6.0  \n",
       "1                       CCs Nacho Cheese    175g         3        6.3  \n",
       "2         Smiths Crinkle Cut  Chips Chicken 170g         2        2.9  \n",
       "3         Smiths Chip Thinly  S/Cream&Onion 175g         5       15.0  \n",
       "4       Kettle Tortilla ChpsHny&Jlpno Chili 150g         3       13.8  \n",
       "...                                          ...       ...        ...  \n",
       "264831   Kettle Sweet Chilli And Sour Cream 175g         2       10.8  \n",
       "264832             Tostitos Splash Of  Lime 175g         1        4.4  \n",
       "264833                  Doritos Mexicana    170g         2        8.8  \n",
       "264834   Doritos Corn Chip Mexican Jalapeno 150g         2        7.8  \n",
       "264835             Tostitos Splash Of  Lime 175g         2        8.8  \n",
       "\n",
       "[264836 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform basic text analysis: \n",
    "# remove special characters \n",
    "transactionData['PROD_NAME'] = transactionData['PROD_NAME'].map(lambda x: re.sub(r'\\W+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove products that are not chips\n",
    "Prod_name_pt = transactionData.groupby(['PROD_NAME'])['DATE'].count().reset_index()\n",
    "Prod_name_pt.rename(columns={'DATE': 'COUNT'}, inplace=True)\n",
    "Prod_name_pt_clean = transactionData[~transactionData['PROD_NAME'].str.contains('Salsa')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no nulls in the columns but product quantity appears to have an outlier which we should investigate\n",
    "# further. Let’s investigate further the case where 200 packets of chips are bought in one transaction.\n",
    "# remove outliers: production quantity greater than 200. \n",
    "transactionData_clean = Prod_name_pt_clean[Prod_name_pt_clean['PROD_QTY']<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any missing dates\n",
    "transactionData_clean['DATE'].nunique()\n",
    "# totally 364 different dates, one date is missing\n",
    "set(transactionData_clean['DATE']) \n",
    "\n",
    "# find the one missing date which is 2018-12-25, which makes sense because all shops closed on Christmas holiday. \n",
    "k = pd.date_range(start=\"2018-07-01\", end=\"2019-06-30\").difference(transactionData_clean.DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if pack size is reasonable by extracting the last a few digits of PROD_NAME\n",
    "transactionData_clean['PACK_SIZE'] = transactionData_clean[\"PROD_NAME\"].str.extract(\"(\\d*\\.?\\d+)\", expand=True)\n",
    "transactionData_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the largest pack size is 380g and the smallest size is 70g, which are reasonable. \n",
    "pack_size_pt = transactionData_clean.groupby(['PACK_SIZE'])['DATE'].count().reset_index()\n",
    "pack_size_pt.rename(columns={'DATE': 'COUNT'}, inplace=True)\n",
    "pack_size_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check brand names\n",
    "brand_ls = ['RED','SNBTS','INFZNS','WW','SMITH','NCC','DORITO','GRAIN',\n",
    "            'RRD','SUNBITES','INFUZIONS','WOOLWORTHS','SMITHS','NATURAL','DORITOS','GRNWVES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform summary statistics table\n",
    "transactionData_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Examine Customer Data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check LIFESTAGE column\n",
    "lifestage_pt = customerData.groupby(['LIFESTAGE'])['LYLTY_CARD_NBR'].count().reset_index()\n",
    "lifestage_pt.rename(columns={'LYLTY_CARD_NBR': 'COUNT'}, inplace=True)\n",
    "lifestage_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check PREMIUM_CUSTOMER column\n",
    "premium_pt = customerData.groupby(['PREMIUM_CUSTOMER'])['LYLTY_CARD_NBR'].count().reset_index()\n",
    "premium_pt.rename(columns={'LYLTY_CARD_NBR': 'COUNT'}, inplace=True)\n",
    "premium_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No issue with LIFESTAGE and PREMIUM_CUSTOMER columns\n",
    "# Join TRANSACTION and CUSTOMER tables together\n",
    "# As the number of rows in data is the same as that of transactionData, we can be sure that no duplicates were created.\n",
    "joint_df = transactionData.merge(customerData, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after left join, check if the newly added columns have null values\n",
    "joint_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a joint data set for further analysis\n",
    "# joint_df.to_csv(filepath+'QVI_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Analysis on customer segments\n",
    "    1. Define metrics of interest to the client\n",
    "        ① who spends the most on chips (total sales), \n",
    "        describing customers by lifestage and how premium their general purchasing beahaviour is\n",
    "        ② how many customers are in each segment\n",
    "        ③ how many chips are bought per customer by segment\n",
    "        ④ what's the average chip price by customer segment\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate TOTAL SALES by LIFESTAGE and PREMIUM_CUSTOMER \n",
    "# describe which customer segment contribute most to chip sales\n",
    "lifestage_df = joint_df.groupby(['LIFESTAGE','PREMIUM_CUSTOMER'])['TOT_SALES'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestage_df['%'] = round(100 * lifestage_df['TOT_SALES']  / lifestage_df['TOT_SALES'].sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lifestage_df = lifestage_df.drop(columns = ['TOT_SALES'])\n",
    "lifestage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestage_df.plot.bar(x='LIFESTAGE', stacked=True, title='Total Sales by Customer Segments')\n",
    "# Sales are coming mainly from Budget - older families, Mainstream - young singles/couples, and Mainstream - retirees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestage_df = joint_df.groupby(['PREMIUM_CUSTOMER','LIFESTAGE'])['TOT_SALES'].sum().reset_index()\n",
    "lifestage_df['%'] = round(100 * lifestage_df['TOT_SALES']  / lifestage_df['TOT_SALES'].sum(), 2)\n",
    "# There are more Mainstream - young singles/couples and Mainstream - retirees who buy chips. This contributes\n",
    "# to there being more sales to these customer segments but this is not a major driver for the Budget\n",
    "# - Older families segment.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifestage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of units of chips being bought per customer\n",
    "# note: perform 'count' aggregate function on LYLTY_CARD_NBR, \n",
    "# and perform 'sum' aggregate function on PROD_QTY\n",
    "avg_units_df_cust = joint_df.groupby(['LIFESTAGE','PREMIUM_CUSTOMER'])['LYLTY_CARD_NBR'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_units_df_cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_units_df_qty = joint_df.groupby(['LIFESTAGE','PREMIUM_CUSTOMER'])['PROD_QTY'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_units_df_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join two sub-df on LIFESTAGE\n",
    "avg_units_df = avg_units_df_cust.merge(avg_units_df_qty, on = ['LIFESTAGE','PREMIUM_CUSTOMER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_units_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_units_df['avg units/customer'] = round(avg_units_df['PROD_QTY']/avg_units_df['LYLTY_CARD_NBR'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_units_df.sort_values('LIFESTAGE')\n",
    "# older families and younger families in general buy more chips per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average chip price by customer segment\n",
    "avg_price = joint_df.groupby(['LIFESTAGE','PREMIUM_CUSTOMER'])['TOT_SALES','PROD_QTY'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price['avg price/unit'] = round(avg_price['TOT_SALES']/avg_price['PROD_QTY'], 2)\n",
    "avg_price.sort_values('avg price/unit', ascending = False)\n",
    "# Mainstream midage and young singles and couples are more willing to pay more per packet of chips compared to their budget and premium counterparts.\n",
    "\n",
    "# since the difference is not large, can check if this difference is statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Deep dive into specific customer segments for insights\n",
    "Look at Mainstreams-Young/Single Couples customers who contribute the most to sales and retain them\n",
    "    1. if Mainstream tend to buy a particular brand of chips\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lifestage = ['YOUNG SINGLES/COUPLES']\n",
    "target_prem_cust = ['Mainstream']\n",
    "\n",
    "target_qty = joint_df[joint_df['LIFESTAGE'].isin(target_lifestage) & joint_df['PREMIUM_CUSTOMER'].isin(target_prem_cust)]\n",
    "non_target_qty = joint_df[~(joint_df['LIFESTAGE'].isin(target_lifestage) & joint_df['PREMIUM_CUSTOMER'].isin(target_prem_cust))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_qty = target_qty.groupby(['PROD_NAME'])['PROD_QTY'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_qty.rename(columns={'PROD_QTY': 'PROD_QTY_target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target_qty = non_target_qty.groupby(['PROD_NAME'])['PROD_QTY'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target_qty.rename(columns={'PROD_QTY': 'PROD_QTY_non_target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qty_df = target_qty.merge(non_target_qty, on = 'PROD_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qty_df['Total_Qty'] = qty_df['PROD_QTY_target'] + qty_df['PROD_QTY_non_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qty_df\n",
    "# We can see that :\n",
    "# • Mainstream young singles/couples are 23% more likely to purchase Tyrrells chips compared to the rest of the population\n",
    "# • Mainstream young singles/couples are 56% less likely to purchase Burger Rings compared to the rest of the population"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
